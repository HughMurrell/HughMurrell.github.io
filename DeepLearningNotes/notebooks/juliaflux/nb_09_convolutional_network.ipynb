{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognizing handwritten digits using a convolutional network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using Flux, Flux.Data.MNIST, Images, Statistics\n",
    "using Flux: onehotbatch, onecold, crossentropy, throttle\n",
    "using Base.Iterators: repeated, partition\n",
    "using Printf, BSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we read in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = MNIST.labels();\n",
    "images = MNIST.images();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "28×28 Array{Gray{N0f8},2} with eltype Gray{Normed{UInt8,8}}:\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " ⋮                                 ⋱                                  \n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_minibatch (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bundle images together with labels and group into minibatchess\n",
    "function make_minibatch(X, Y, idxs)\n",
    "    X_batch = Array{Float32}(undef, size(X[1])..., 1, length(idxs))\n",
    "    for i in 1:length(idxs)\n",
    "        X_batch[:, :, :, i] = Float32.(X[idxs[i]])\n",
    "    end\n",
    "    Y_batch = onehotbatch(Y[idxs], 0:9)\n",
    "    return (X_batch, Y_batch)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "mb_idxs = partition(1:length(images), batch_size)\n",
    "train_set = [make_minibatch(images, labels, i) for i in mb_idxs];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare test set as one giant minibatch:\n",
    "test_images = MNIST.images(:test)\n",
    "test_labels = MNIST.labels(:test)\n",
    "test_set = make_minibatch(test_images, test_labels, 1:length(test_images));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up a convolutional neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mC\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mv\u001b[22m \u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mv\u001b[22mert \u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mv\u001b[22mexhull Depthwise\u001b[0m\u001b[1mC\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mv\u001b[22m \u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1mo\u001b[22mde_\u001b[0m\u001b[1mn\u001b[22mati\u001b[0m\u001b[1mv\u001b[22me @\u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1mo\u001b[22mde_\u001b[0m\u001b[1mn\u001b[22mati\u001b[0m\u001b[1mv\u001b[22me \u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mn\u001b[22mj\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Conv(size, in=>out)\n",
       "Conv(size, in=>out, relu)\n",
       "```\n",
       "\n",
       "Standard convolutional layer. `size` should be a tuple like `(2, 2)`. `in` and `out` specify the number of input and output channels respectively.\n",
       "\n",
       "Data should be stored in WHCN order. In other words, a 100×100 RGB image would be a `100×100×3×1` array, and a batch of 50 would be a `100×100×3×50` array.\n",
       "\n",
       "Takes the keyword arguments `pad`, `stride` and `dilation`.\n"
      ],
      "text/plain": [
       "\u001b[36m  Conv(size, in=>out)\u001b[39m\n",
       "\u001b[36m  Conv(size, in=>out, relu)\u001b[39m\n",
       "\n",
       "  Standard convolutional layer. \u001b[36msize\u001b[39m should be a tuple like \u001b[36m(2, 2)\u001b[39m. \u001b[36min\u001b[39m and \u001b[36mout\u001b[39m\n",
       "  specify the number of input and output channels respectively.\n",
       "\n",
       "  Data should be stored in WHCN order. In other words, a 100×100 RGB image\n",
       "  would be a \u001b[36m100×100×3×1\u001b[39m array, and a batch of 50 would be a \u001b[36m100×100×3×50\u001b[39m\n",
       "  array.\n",
       "\n",
       "  Takes the keyword arguments \u001b[36mpad\u001b[39m, \u001b[36mstride\u001b[39m and \u001b[36mdilation\u001b[39m."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Constructing model...\n",
      "└ @ Main In[16]:4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Chain(Conv((3, 3), 1=>16, NNlib.relu), getfield(Main, Symbol(\"##9#13\"))(), Conv((3, 3), 16=>32, NNlib.relu), getfield(Main, Symbol(\"##10#14\"))(), Conv((3, 3), 32=>32, NNlib.relu), getfield(Main, Symbol(\"##11#15\"))(), getfield(Main, Symbol(\"##12#16\"))(), Dense(288, 10), NNlib.softmax)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define our model.  \n",
    "# We will use a simple convolutional architecture with\n",
    "# three iterations of Conv -> ReLU -> MaxPool, \n",
    "# followed by a final Dense layer that\n",
    "# feeds into a softmax probability output.\n",
    "@info(\"Constructing model...\")\n",
    "model = Chain(\n",
    "    # First convolution, operating upon a 28x28 image\n",
    "    Conv((3, 3), 1=>16, pad=(1,1), relu),\n",
    "    x -> maxpool(x, (2,2)),\n",
    "\n",
    "    # Second convolution, operating upon a 14x14 image\n",
    "    Conv((3, 3), 16=>32, pad=(1,1), relu),\n",
    "    x -> maxpool(x, (2,2)),\n",
    "\n",
    "    # Third convolution, operating upon a 7x7 image\n",
    "    Conv((3, 3), 32=>32, pad=(1,1), relu),\n",
    "    x -> maxpool(x, (2,2)),\n",
    "\n",
    "    # Reshape 3d tensor into a 2d one, \n",
    "    # at this point it should be (3, 3, 32, N)\n",
    "    # which is where we get the 288 in the `Dense` \n",
    "    # layer below:\n",
    "    x -> reshape(x, :, size(x, 4)),\n",
    "    Dense(288, 10),\n",
    "\n",
    "    # Finally, softmax to get nice probabilities\n",
    "    softmax,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tracked 10×128 Array{Float32,2}:\n",
       " 0.00180607  0.000692555  0.00112681  0.00143349  …  0.000432991  0.000174138\n",
       " 0.0114105   0.00338544   0.0116013   0.00103415     0.0154825    0.00153919 \n",
       " 0.0005193   0.00159591   0.00187203  0.0041794      0.000604512  0.000589073\n",
       " 0.199137    0.233878     0.11968     0.0945053      0.125249     0.131407   \n",
       " 0.0221129   0.112573     0.0940939   0.0164832      0.0229341    0.0114338  \n",
       " 0.0900496   0.114881     0.0957023   0.0272095   …  0.0401364    0.0588964  \n",
       " 0.0176924   0.00390941   0.0110788   0.00510167     0.0124916    0.000720865\n",
       " 0.325168    0.346883     0.249772    0.54771        0.442028     0.521354   \n",
       " 0.160219    0.00885474   0.036308    0.00529267     0.0256448    0.00922572 \n",
       " 0.171885    0.173348     0.378765    0.297051       0.314997     0.26466    "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure our model is nicely precompiled \n",
    "# before starting our training loop\n",
    "model(train_set[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `loss()` calculates the crossentropy loss \n",
    "# between our prediction `y_hat`\n",
    "# (calculated from `model(x)`) and \n",
    "# the ground truth `y`.  \n",
    "# We augment the data a bit, \n",
    "# adding gaussian random noise to our image \n",
    "# to make it more robust.\n",
    "function loss(x, y)\n",
    "    # We augment `x` a little bit here, \n",
    "    # adding in random noise\n",
    "    x_aug = x .+ 0.1*gpu(randn(eltype(x), size(x)))\n",
    "\n",
    "    y_hat = model(x_aug)\n",
    "    return crossentropy(y_hat, y)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(x, y) = mean(onecold(model(x)) .== onecold(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Beginning training loop...\n",
      "└ @ Main In[27]:5\n",
      "┌ Info: [1]: Test accuracy: 0.9791\n",
      "└ @ Main In[27]:15\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main In[27]:25\n",
      "┌ Info: [2]: Test accuracy: 0.9834\n",
      "└ @ Main In[27]:15\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main In[27]:25\n",
      "┌ Info: [3]: Test accuracy: 0.9860\n",
      "└ @ Main In[27]:15\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main In[27]:25\n",
      "┌ Info: [4]: Test accuracy: 0.9849\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [5]: Test accuracy: 0.9873\n",
      "└ @ Main In[27]:15\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main In[27]:25\n",
      "┌ Info: [6]: Test accuracy: 0.9878\n",
      "└ @ Main In[27]:15\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main In[27]:25\n",
      "┌ Info: [7]: Test accuracy: 0.9879\n",
      "└ @ Main In[27]:15\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main In[27]:25\n",
      "┌ Info: [8]: Test accuracy: 0.9885\n",
      "└ @ Main In[27]:15\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main In[27]:25\n",
      "┌ Info: [9]: Test accuracy: 0.9884\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [10]: Test accuracy: 0.9894\n",
      "└ @ Main In[27]:15\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main In[27]:25\n",
      "┌ Info: [11]: Test accuracy: 0.9888\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [12]: Test accuracy: 0.9878\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [13]: Test accuracy: 0.9891\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [14]: Test accuracy: 0.9867\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [15]: Test accuracy: 0.9874\n",
      "└ @ Main In[27]:15\n",
      "┌ Warning:  -> Haven't improved in a while, dropping learning rate to 0.0001!\n",
      "└ @ Main In[27]:34\n",
      "┌ Info: [16]: Test accuracy: 0.9910\n",
      "└ @ Main In[27]:15\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main In[27]:25\n",
      "┌ Info: [17]: Test accuracy: 0.9903\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [18]: Test accuracy: 0.9904\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [19]: Test accuracy: 0.9910\n",
      "└ @ Main In[27]:15\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main In[27]:25\n",
      "┌ Info: [20]: Test accuracy: 0.9907\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [21]: Test accuracy: 0.9907\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [22]: Test accuracy: 0.9906\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [23]: Test accuracy: 0.9907\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [24]: Test accuracy: 0.9911\n",
      "└ @ Main In[27]:15\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main In[27]:25\n",
      "┌ Info: [25]: Test accuracy: 0.9913\n",
      "└ @ Main In[27]:15\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main In[27]:25\n",
      "┌ Info: [26]: Test accuracy: 0.9912\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [27]: Test accuracy: 0.9911\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [28]: Test accuracy: 0.9912\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [29]: Test accuracy: 0.9916\n",
      "└ @ Main In[27]:15\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main In[27]:25\n",
      "┌ Info: [30]: Test accuracy: 0.9914\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [31]: Test accuracy: 0.9909\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [32]: Test accuracy: 0.9917\n",
      "└ @ Main In[27]:15\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main In[27]:25\n",
      "┌ Info: [33]: Test accuracy: 0.9913\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [34]: Test accuracy: 0.9916\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [35]: Test accuracy: 0.9911\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [36]: Test accuracy: 0.9911\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [37]: Test accuracy: 0.9907\n",
      "└ @ Main In[27]:15\n",
      "┌ Warning:  -> Haven't improved in a while, dropping learning rate to 1.0e-5!\n",
      "└ @ Main In[27]:34\n",
      "┌ Info: [38]: Test accuracy: 0.9908\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [39]: Test accuracy: 0.9908\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [40]: Test accuracy: 0.9912\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [41]: Test accuracy: 0.9912\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [42]: Test accuracy: 0.9911\n",
      "└ @ Main In[27]:15\n",
      "┌ Warning:  -> Haven't improved in a while, dropping learning rate to 1.0000000000000002e-6!\n",
      "└ @ Main In[27]:34\n",
      "┌ Info: [43]: Test accuracy: 0.9912\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [44]: Test accuracy: 0.9913\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [45]: Test accuracy: 0.9913\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [46]: Test accuracy: 0.9913\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [47]: Test accuracy: 0.9910\n",
      "└ @ Main In[27]:15\n",
      "┌ Warning:  -> Haven't improved in a while, dropping learning rate to 1.0000000000000002e-7!\n",
      "└ @ Main In[27]:34\n",
      "┌ Info: [48]: Test accuracy: 0.9910\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [49]: Test accuracy: 0.9910\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [50]: Test accuracy: 0.9910\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [51]: Test accuracy: 0.9910\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [52]: Test accuracy: 0.9910\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [53]: Test accuracy: 0.9910\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [54]: Test accuracy: 0.9910\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [55]: Test accuracy: 0.9910\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [56]: Test accuracy: 0.9910\n",
      "└ @ Main In[27]:15\n",
      "┌ Info: [57]: Test accuracy: 0.9910\n",
      "└ @ Main In[27]:15\n",
      "┌ Warning:  -> We're calling this converged.\n",
      "└ @ Main In[27]:41\n"
     ]
    }
   ],
   "source": [
    "# Train our model with the given training set \n",
    "# using the ADAM optimizer and\n",
    "# printing out performance against \n",
    "# the test set as we go.\n",
    "opt = ADAM(0.001)\n",
    "\n",
    "@info(\"Beginning training loop...\")\n",
    "best_acc = 0.0\n",
    "last_improvement = 0\n",
    "for epoch_idx in 1:100\n",
    "    global best_acc, last_improvement\n",
    "    # Train for a single epoch\n",
    "    Flux.train!(loss, params(model), train_set, opt)\n",
    "\n",
    "    # Calculate accuracy:\n",
    "    acc = accuracy(test_set...)\n",
    "    @info(@sprintf(\"[%d]: Test accuracy: %.4f\", \n",
    "            epoch_idx, acc))\n",
    "    \n",
    "    # If our accuracy is good enough, quit out.\n",
    "    if acc >= 0.999\n",
    "        @info(\" -> Early-exiting: We reached our target accuracy of 99.9%\")\n",
    "        break\n",
    "    end\n",
    "\n",
    "    # If this is the best accuracy we've seen so far, \n",
    "    # save the model using the BSON package\n",
    "    if acc >= best_acc\n",
    "        @info(\" -> New best accuracy! Saving model out to mnist_conv.bson\")\n",
    "        BSON.@save \"mnist_conv.bson\" model epoch_idx acc\n",
    "        best_acc = acc\n",
    "        last_improvement = epoch_idx\n",
    "    end\n",
    "\n",
    "    # If we haven't seen improvement in 5 epochs, \n",
    "    # drop our learning rate:\n",
    "    if epoch_idx - last_improvement >= 5 && opt.eta > 1e-6\n",
    "        opt.eta /= 10.0\n",
    "        @warn(\" -> Haven't improved in a while, dropping learning rate to $(opt.eta)!\")\n",
    "\n",
    "        # After dropping learning rate, \n",
    "        # give it a few epochs to improve\n",
    "        last_improvement = epoch_idx\n",
    "    end\n",
    "\n",
    "    if epoch_idx - last_improvement >= 10\n",
    "        @warn(\" -> We're calling this converged.\")\n",
    "        break\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 3
}
